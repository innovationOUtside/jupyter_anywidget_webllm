{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# webllm anywidget\n",
    "\n",
    "A simple `anywidget` for interacting with SmolLM2 generative LLM models via webllm; optionally provide a template as a JSON schema to structure the output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple headless operation\n",
    "\n",
    "We can use the widget in a \"headless\" way to run the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 1
      },
      "text/plain": [
       "webllmWidget(headless=True, response={'status': 'initialising'})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "({'status': 'ready', 'time': 3.4547698497772217},\n",
       " {'widget': 'jupyter_anywidget_webllm',\n",
       "  'webllm_model': 'SmolLM2-1.7B-Instruct-q4f16_1-MLC'})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from jupyter_anywidget_webllm import webllm_headless\n",
    "\n",
    "%load_ext jupyter_anywidget_webllm\n",
    "\n",
    "# Load the widget\n",
    "w = webllm_headless()\n",
    "\n",
    "# Wait for webllm to load\n",
    "w.ready()\n",
    "\n",
    "# Display status\n",
    "w.response, w.about"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'model': 'https://huggingface.co/mlc-ai/Llama-3.2-1B-Instruct-q4f32_1-MLC',\n",
       "  'model_id': 'Llama-3.2-1B-Instruct-q4f32_1-MLC',\n",
       "  'model_lib': 'https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_48/Llama-3.2-1B-Instruct-q4f32_1-ctx4k_cs1k-webgpu.wasm',\n",
       "  'vram_required_MB': 1128.82,\n",
       "  'low_resource_required': True,\n",
       "  'overrides': {'context_window_size': 4096}},\n",
       " {'model': 'https://huggingface.co/mlc-ai/Llama-3.2-1B-Instruct-q4f16_1-MLC',\n",
       "  'model_id': 'Llama-3.2-1B-Instruct-q4f16_1-MLC',\n",
       "  'model_lib': 'https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_48/Llama-3.2-1B-Instruct-q4f16_1-ctx4k_cs1k-webgpu.wasm',\n",
       "  'vram_required_MB': 879.04,\n",
       "  'low_resource_required': True,\n",
       "  'overrides': {'context_window_size': 4096}},\n",
       " {'model': 'https://huggingface.co/mlc-ai/Llama-3.2-1B-Instruct-q0f32-MLC',\n",
       "  'model_id': 'Llama-3.2-1B-Instruct-q0f32-MLC',\n",
       "  'model_lib': 'https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_48/Llama-3.2-1B-Instruct-q0f32-ctx4k_cs1k-webgpu.wasm',\n",
       "  'vram_required_MB': 5106.26,\n",
       "  'low_resource_required': True,\n",
       "  'overrides': {'context_window_size': 4096}},\n",
       " {'model': 'https://huggingface.co/mlc-ai/Llama-3.2-1B-Instruct-q0f16-MLC',\n",
       "  'model_id': 'Llama-3.2-1B-Instruct-q0f16-MLC',\n",
       "  'model_lib': 'https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_48/Llama-3.2-1B-Instruct-q0f16-ctx4k_cs1k-webgpu.wasm',\n",
       "  'vram_required_MB': 2573.13,\n",
       "  'low_resource_required': True,\n",
       "  'overrides': {'context_window_size': 4096}},\n",
       " {'model': 'https://huggingface.co/mlc-ai/Llama-3.2-3B-Instruct-q4f32_1-MLC',\n",
       "  'model_id': 'Llama-3.2-3B-Instruct-q4f32_1-MLC',\n",
       "  'model_lib': 'https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_48/Llama-3.2-3B-Instruct-q4f32_1-ctx4k_cs1k-webgpu.wasm',\n",
       "  'vram_required_MB': 2951.51,\n",
       "  'low_resource_required': True,\n",
       "  'overrides': {'context_window_size': 4096}},\n",
       " {'model': 'https://huggingface.co/mlc-ai/Llama-3.2-3B-Instruct-q4f16_1-MLC',\n",
       "  'model_id': 'Llama-3.2-3B-Instruct-q4f16_1-MLC',\n",
       "  'model_lib': 'https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_48/Llama-3.2-3B-Instruct-q4f16_1-ctx4k_cs1k-webgpu.wasm',\n",
       "  'vram_required_MB': 2263.69,\n",
       "  'low_resource_required': True,\n",
       "  'overrides': {'context_window_size': 4096}},\n",
       " {'model': 'https://huggingface.co/mlc-ai/Llama-3.1-8B-Instruct-q4f32_1-MLC',\n",
       "  'model_id': 'Llama-3.1-8B-Instruct-q4f32_1-MLC-1k',\n",
       "  'model_lib': 'https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_48/Llama-3_1-8B-Instruct-q4f32_1-ctx4k_cs1k-webgpu.wasm',\n",
       "  'vram_required_MB': 5295.7,\n",
       "  'low_resource_required': True,\n",
       "  'overrides': {'context_window_size': 1024}},\n",
       " {'model': 'https://huggingface.co/mlc-ai/Llama-3.1-8B-Instruct-q4f16_1-MLC',\n",
       "  'model_id': 'Llama-3.1-8B-Instruct-q4f16_1-MLC-1k',\n",
       "  'model_lib': 'https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_48/Llama-3_1-8B-Instruct-q4f16_1-ctx4k_cs1k-webgpu.wasm',\n",
       "  'vram_required_MB': 4598.34,\n",
       "  'low_resource_required': True,\n",
       "  'overrides': {'context_window_size': 1024}},\n",
       " {'model': 'https://huggingface.co/mlc-ai/Llama-3.1-8B-Instruct-q4f32_1-MLC',\n",
       "  'model_id': 'Llama-3.1-8B-Instruct-q4f32_1-MLC',\n",
       "  'model_lib': 'https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_48/Llama-3_1-8B-Instruct-q4f32_1-ctx4k_cs1k-webgpu.wasm',\n",
       "  'vram_required_MB': 6101.01,\n",
       "  'low_resource_required': False,\n",
       "  'overrides': {'context_window_size': 4096}},\n",
       " {'model': 'https://huggingface.co/mlc-ai/Llama-3.1-8B-Instruct-q4f16_1-MLC',\n",
       "  'model_id': 'Llama-3.1-8B-Instruct-q4f16_1-MLC',\n",
       "  'model_lib': 'https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_48/Llama-3_1-8B-Instruct-q4f16_1-ctx4k_cs1k-webgpu.wasm',\n",
       "  'vram_required_MB': 5001,\n",
       "  'low_resource_required': False,\n",
       "  'overrides': {'context_window_size': 4096}},\n",
       " {'model': 'https://huggingface.co/mlc-ai/Hermes-2-Theta-Llama-3-8B-q4f16_1-MLC',\n",
       "  'model_id': 'Hermes-2-Theta-Llama-3-8B-q4f16_1-MLC',\n",
       "  'model_lib': 'https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_48/Llama-3-8B-Instruct-q4f16_1-ctx4k_cs1k-webgpu.wasm',\n",
       "  'vram_required_MB': 4976.13,\n",
       "  'low_resource_required': False,\n",
       "  'overrides': {'context_window_size': 4096}},\n",
       " {'model': 'https://huggingface.co/mlc-ai/Hermes-2-Theta-Llama-3-8B-q4f32_1-MLC',\n",
       "  'model_id': 'Hermes-2-Theta-Llama-3-8B-q4f32_1-MLC',\n",
       "  'model_lib': 'https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_48/Llama-3-8B-Instruct-q4f32_1-ctx4k_cs1k-webgpu.wasm',\n",
       "  'vram_required_MB': 6051.27,\n",
       "  'low_resource_required': False,\n",
       "  'overrides': {'context_window_size': 4096}},\n",
       " {'model': 'https://huggingface.co/mlc-ai/Hermes-2-Pro-Llama-3-8B-q4f16_1-MLC',\n",
       "  'model_id': 'Hermes-2-Pro-Llama-3-8B-q4f16_1-MLC',\n",
       "  'model_lib': 'https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_48/Llama-3-8B-Instruct-q4f16_1-ctx4k_cs1k-webgpu.wasm',\n",
       "  'vram_required_MB': 4976.13,\n",
       "  'low_resource_required': False,\n",
       "  'overrides': {'context_window_size': 4096}},\n",
       " {'model': 'https://huggingface.co/mlc-ai/Hermes-2-Pro-Llama-3-8B-q4f32_1-MLC',\n",
       "  'model_id': 'Hermes-2-Pro-Llama-3-8B-q4f32_1-MLC',\n",
       "  'model_lib': 'https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_48/Llama-3-8B-Instruct-q4f32_1-ctx4k_cs1k-webgpu.wasm',\n",
       "  'vram_required_MB': 6051.27,\n",
       "  'low_resource_required': False,\n",
       "  'overrides': {'context_window_size': 4096}},\n",
       " {'model': 'https://huggingface.co/mlc-ai/Hermes-3-Llama-3.1-8B-q4f32_1-MLC',\n",
       "  'model_id': 'Hermes-3-Llama-3.1-8B-q4f32_1-MLC',\n",
       "  'model_lib': 'https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_48/Llama-3_1-8B-Instruct-q4f32_1-ctx4k_cs1k-webgpu.wasm',\n",
       "  'vram_required_MB': 5779.27,\n",
       "  'low_resource_required': False,\n",
       "  'overrides': {'context_window_size': 4096}},\n",
       " {'model': 'https://huggingface.co/mlc-ai/Hermes-3-Llama-3.1-8B-q4f16_1-MLC',\n",
       "  'model_id': 'Hermes-3-Llama-3.1-8B-q4f16_1-MLC',\n",
       "  'model_lib': 'https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_48/Llama-3_1-8B-Instruct-q4f16_1-ctx4k_cs1k-webgpu.wasm',\n",
       "  'vram_required_MB': 4876.13,\n",
       "  'low_resource_required': False,\n",
       "  'overrides': {'context_window_size': 4096}},\n",
       " {'model': 'https://huggingface.co/mlc-ai/Hermes-2-Pro-Mistral-7B-q4f16_1-MLC',\n",
       "  'model_id': 'Hermes-2-Pro-Mistral-7B-q4f16_1-MLC',\n",
       "  'model_lib': 'https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_48/Mistral-7B-Instruct-v0.3-q4f16_1-ctx4k_cs1k-webgpu.wasm',\n",
       "  'vram_required_MB': 4033.28,\n",
       "  'low_resource_required': False,\n",
       "  'required_features': ['shader-f16'],\n",
       "  'overrides': {'context_window_size': 4096, 'sliding_window_size': -1}},\n",
       " {'model': 'https://huggingface.co/mlc-ai/Phi-3.5-mini-instruct-q4f16_1-MLC',\n",
       "  'model_id': 'Phi-3.5-mini-instruct-q4f16_1-MLC',\n",
       "  'model_lib': 'https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_48/Phi-3.5-mini-instruct-q4f16_1-ctx4k_cs1k-webgpu.wasm',\n",
       "  'vram_required_MB': 3672.07,\n",
       "  'low_resource_required': False,\n",
       "  'overrides': {'context_window_size': 4096}},\n",
       " {'model': 'https://huggingface.co/mlc-ai/Phi-3.5-mini-instruct-q4f32_1-MLC',\n",
       "  'model_id': 'Phi-3.5-mini-instruct-q4f32_1-MLC',\n",
       "  'model_lib': 'https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_48/Phi-3.5-mini-instruct-q4f32_1-ctx4k_cs1k-webgpu.wasm',\n",
       "  'vram_required_MB': 5483.12,\n",
       "  'low_resource_required': False,\n",
       "  'overrides': {'context_window_size': 4096}},\n",
       " {'model': 'https://huggingface.co/mlc-ai/Phi-3.5-mini-instruct-q4f16_1-MLC',\n",
       "  'model_id': 'Phi-3.5-mini-instruct-q4f16_1-MLC-1k',\n",
       "  'model_lib': 'https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_48/Phi-3.5-mini-instruct-q4f16_1-ctx4k_cs1k-webgpu.wasm',\n",
       "  'vram_required_MB': 2520.07,\n",
       "  'low_resource_required': True,\n",
       "  'overrides': {'context_window_size': 1024}},\n",
       " {'model': 'https://huggingface.co/mlc-ai/Phi-3.5-mini-instruct-q4f32_1-MLC',\n",
       "  'model_id': 'Phi-3.5-mini-instruct-q4f32_1-MLC-1k',\n",
       "  'model_lib': 'https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_48/Phi-3.5-mini-instruct-q4f32_1-ctx4k_cs1k-webgpu.wasm',\n",
       "  'vram_required_MB': 3179.12,\n",
       "  'low_resource_required': True,\n",
       "  'overrides': {'context_window_size': 1024}},\n",
       " {'model': 'https://huggingface.co/mlc-ai/Phi-3.5-vision-instruct-q4f16_1-MLC',\n",
       "  'model_id': 'Phi-3.5-vision-instruct-q4f16_1-MLC',\n",
       "  'model_lib': 'https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_48/Phi-3.5-vision-instruct-q4f16_1-ctx4k_cs2k-webgpu.wasm',\n",
       "  'vram_required_MB': 3952.18,\n",
       "  'low_resource_required': True,\n",
       "  'overrides': {'context_window_size': 4096},\n",
       "  'model_type': 2},\n",
       " {'model': 'https://huggingface.co/mlc-ai/Phi-3.5-vision-instruct-q4f32_1-MLC',\n",
       "  'model_id': 'Phi-3.5-vision-instruct-q4f32_1-MLC',\n",
       "  'model_lib': 'https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_48/Phi-3.5-vision-instruct-q4f32_1-ctx4k_cs2k-webgpu.wasm',\n",
       "  'vram_required_MB': 5879.84,\n",
       "  'low_resource_required': True,\n",
       "  'overrides': {'context_window_size': 4096},\n",
       "  'model_type': 2},\n",
       " {'model': 'https://huggingface.co/mlc-ai/Mistral-7B-Instruct-v0.3-q4f16_1-MLC',\n",
       "  'model_id': 'Mistral-7B-Instruct-v0.3-q4f16_1-MLC',\n",
       "  'model_lib': 'https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_48/Mistral-7B-Instruct-v0.3-q4f16_1-ctx4k_cs1k-webgpu.wasm',\n",
       "  'vram_required_MB': 4573.39,\n",
       "  'low_resource_required': False,\n",
       "  'required_features': ['shader-f16'],\n",
       "  'overrides': {'context_window_size': 4096, 'sliding_window_size': -1}},\n",
       " {'model': 'https://huggingface.co/mlc-ai/Mistral-7B-Instruct-v0.3-q4f32_1-MLC',\n",
       "  'model_id': 'Mistral-7B-Instruct-v0.3-q4f32_1-MLC',\n",
       "  'model_lib': 'https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_48/Mistral-7B-Instruct-v0.3-q4f32_1-ctx4k_cs1k-webgpu.wasm',\n",
       "  'vram_required_MB': 5619.27,\n",
       "  'low_resource_required': False,\n",
       "  'overrides': {'context_window_size': 4096, 'sliding_window_size': -1}},\n",
       " {'model': 'https://huggingface.co/mlc-ai/Mistral-7B-Instruct-v0.2-q4f16_1-MLC',\n",
       "  'model_id': 'Mistral-7B-Instruct-v0.2-q4f16_1-MLC',\n",
       "  'model_lib': 'https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_48/Mistral-7B-Instruct-v0.3-q4f16_1-ctx4k_cs1k-webgpu.wasm',\n",
       "  'vram_required_MB': 4573.39,\n",
       "  'low_resource_required': False,\n",
       "  'required_features': ['shader-f16'],\n",
       "  'overrides': {'context_window_size': 4096, 'sliding_window_size': -1}},\n",
       " {'model': 'https://huggingface.co/mlc-ai/OpenHermes-2.5-Mistral-7B-q4f16_1-MLC',\n",
       "  'model_id': 'OpenHermes-2.5-Mistral-7B-q4f16_1-MLC',\n",
       "  'model_lib': 'https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_48/Mistral-7B-Instruct-v0.3-q4f16_1-ctx4k_cs1k-webgpu.wasm',\n",
       "  'vram_required_MB': 4573.39,\n",
       "  'low_resource_required': False,\n",
       "  'required_features': ['shader-f16'],\n",
       "  'overrides': {'context_window_size': 4096, 'sliding_window_size': -1}},\n",
       " {'model': 'https://huggingface.co/mlc-ai/NeuralHermes-2.5-Mistral-7B-q4f16_1-MLC',\n",
       "  'model_id': 'NeuralHermes-2.5-Mistral-7B-q4f16_1-MLC',\n",
       "  'model_lib': 'https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_48/Mistral-7B-Instruct-v0.3-q4f16_1-ctx4k_cs1k-webgpu.wasm',\n",
       "  'vram_required_MB': 4573.39,\n",
       "  'low_resource_required': False,\n",
       "  'required_features': ['shader-f16'],\n",
       "  'overrides': {'context_window_size': 4096, 'sliding_window_size': -1}},\n",
       " {'model': 'https://huggingface.co/mlc-ai/WizardMath-7B-V1.1-q4f16_1-MLC',\n",
       "  'model_id': 'WizardMath-7B-V1.1-q4f16_1-MLC',\n",
       "  'model_lib': 'https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_48/Mistral-7B-Instruct-v0.3-q4f16_1-ctx4k_cs1k-webgpu.wasm',\n",
       "  'vram_required_MB': 4573.39,\n",
       "  'low_resource_required': False,\n",
       "  'required_features': ['shader-f16'],\n",
       "  'overrides': {'context_window_size': 4096, 'sliding_window_size': -1}},\n",
       " {'model': 'https://huggingface.co/mlc-ai/SmolLM2-1.7B-Instruct-q4f16_1-MLC',\n",
       "  'model_id': 'SmolLM2-1.7B-Instruct-q4f16_1-MLC',\n",
       "  'model_lib': 'https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_48/SmolLM2-1.7B-Instruct-q4f16_1-ctx4k_cs1k-webgpu.wasm',\n",
       "  'vram_required_MB': 1774.19,\n",
       "  'low_resource_required': True,\n",
       "  'required_features': ['shader-f16'],\n",
       "  'overrides': {'context_window_size': 4096}},\n",
       " {'model': 'https://huggingface.co/mlc-ai/SmolLM2-1.7B-Instruct-q4f32_1-MLC',\n",
       "  'model_id': 'SmolLM2-1.7B-Instruct-q4f32_1-MLC',\n",
       "  'model_lib': 'https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_48/SmolLM2-1.7B-Instruct-q4f32_1-ctx4k_cs1k-webgpu.wasm',\n",
       "  'vram_required_MB': 2692.38,\n",
       "  'low_resource_required': True,\n",
       "  'overrides': {'context_window_size': 4096}},\n",
       " {'model': 'https://huggingface.co/mlc-ai/SmolLM2-360M-Instruct-q0f16-MLC',\n",
       "  'model_id': 'SmolLM2-360M-Instruct-q0f16-MLC',\n",
       "  'model_lib': 'https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_48/SmolLM2-360M-Instruct-q0f16-ctx4k_cs1k-webgpu.wasm',\n",
       "  'vram_required_MB': 871.99,\n",
       "  'low_resource_required': True,\n",
       "  'required_features': ['shader-f16'],\n",
       "  'overrides': {'context_window_size': 4096}},\n",
       " {'model': 'https://huggingface.co/mlc-ai/SmolLM2-360M-Instruct-q0f32-MLC',\n",
       "  'model_id': 'SmolLM2-360M-Instruct-q0f32-MLC',\n",
       "  'model_lib': 'https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_48/SmolLM2-360M-Instruct-q0f32-ctx4k_cs1k-webgpu.wasm',\n",
       "  'vram_required_MB': 1743.99,\n",
       "  'low_resource_required': True,\n",
       "  'overrides': {'context_window_size': 4096}},\n",
       " {'model': 'https://huggingface.co/mlc-ai/SmolLM2-360M-Instruct-q4f16_1-MLC',\n",
       "  'model_id': 'SmolLM2-360M-Instruct-q4f16_1-MLC',\n",
       "  'model_lib': 'https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_48/SmolLM2-360M-Instruct-q4f16_1-ctx4k_cs1k-webgpu.wasm',\n",
       "  'vram_required_MB': 376.06,\n",
       "  'low_resource_required': True,\n",
       "  'required_features': ['shader-f16'],\n",
       "  'overrides': {'context_window_size': 4096}},\n",
       " {'model': 'https://huggingface.co/mlc-ai/SmolLM2-360M-Instruct-q4f32_1-MLC',\n",
       "  'model_id': 'SmolLM2-360M-Instruct-q4f32_1-MLC',\n",
       "  'model_lib': 'https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_48/SmolLM2-360M-Instruct-q4f32_1-ctx4k_cs1k-webgpu.wasm',\n",
       "  'vram_required_MB': 579.61,\n",
       "  'low_resource_required': True,\n",
       "  'overrides': {'context_window_size': 4096}},\n",
       " {'model': 'https://huggingface.co/mlc-ai/SmolLM2-135M-Instruct-q0f16-MLC',\n",
       "  'model_id': 'SmolLM2-135M-Instruct-q0f16-MLC',\n",
       "  'model_lib': 'https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_48/SmolLM2-135M-Instruct-q0f16-ctx4k_cs1k-webgpu.wasm',\n",
       "  'vram_required_MB': 359.69,\n",
       "  'low_resource_required': True,\n",
       "  'required_features': ['shader-f16'],\n",
       "  'overrides': {'context_window_size': 4096}},\n",
       " {'model': 'https://huggingface.co/mlc-ai/SmolLM2-135M-Instruct-q0f32-MLC',\n",
       "  'model_id': 'SmolLM2-135M-Instruct-q0f32-MLC',\n",
       "  'model_lib': 'https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_48/SmolLM2-135M-Instruct-q0f32-ctx4k_cs1k-webgpu.wasm',\n",
       "  'vram_required_MB': 719.38,\n",
       "  'low_resource_required': True,\n",
       "  'overrides': {'context_window_size': 4096}},\n",
       " {'model': 'https://huggingface.co/mlc-ai/gemma-2-2b-it-q4f16_1-MLC',\n",
       "  'model_id': 'gemma-2-2b-it-q4f16_1-MLC',\n",
       "  'model_lib': 'https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_48/gemma-2-2b-it-q4f16_1-ctx4k_cs1k-webgpu.wasm',\n",
       "  'vram_required_MB': 1895.3,\n",
       "  'low_resource_required': False,\n",
       "  'required_features': ['shader-f16'],\n",
       "  'overrides': {'context_window_size': 4096}},\n",
       " {'model': 'https://huggingface.co/mlc-ai/gemma-2-2b-it-q4f32_1-MLC',\n",
       "  'model_id': 'gemma-2-2b-it-q4f32_1-MLC',\n",
       "  'model_lib': 'https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_48/gemma-2-2b-it-q4f32_1-ctx4k_cs1k-webgpu.wasm',\n",
       "  'vram_required_MB': 2508.75,\n",
       "  'low_resource_required': False,\n",
       "  'overrides': {'context_window_size': 4096}},\n",
       " {'model': 'https://huggingface.co/mlc-ai/gemma-2-2b-it-q4f16_1-MLC',\n",
       "  'model_id': 'gemma-2-2b-it-q4f16_1-MLC-1k',\n",
       "  'model_lib': 'https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_48/gemma-2-2b-it-q4f16_1-ctx4k_cs1k-webgpu.wasm',\n",
       "  'vram_required_MB': 1583.3,\n",
       "  'low_resource_required': True,\n",
       "  'required_features': ['shader-f16'],\n",
       "  'overrides': {'context_window_size': 1024}},\n",
       " {'model': 'https://huggingface.co/mlc-ai/gemma-2-2b-it-q4f32_1-MLC',\n",
       "  'model_id': 'gemma-2-2b-it-q4f32_1-MLC-1k',\n",
       "  'model_lib': 'https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_48/gemma-2-2b-it-q4f32_1-ctx4k_cs1k-webgpu.wasm',\n",
       "  'vram_required_MB': 1884.75,\n",
       "  'low_resource_required': True,\n",
       "  'overrides': {'context_window_size': 1024}},\n",
       " {'model': 'https://huggingface.co/mlc-ai/gemma-2-9b-it-q4f16_1-MLC',\n",
       "  'model_id': 'gemma-2-9b-it-q4f16_1-MLC',\n",
       "  'model_lib': 'https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_48/gemma-2-9b-it-q4f16_1-ctx4k_cs1k-webgpu.wasm',\n",
       "  'vram_required_MB': 6422.01,\n",
       "  'low_resource_required': False,\n",
       "  'required_features': ['shader-f16'],\n",
       "  'overrides': {'context_window_size': 4096}},\n",
       " {'model': 'https://huggingface.co/mlc-ai/gemma-2-9b-it-q4f32_1-MLC',\n",
       "  'model_id': 'gemma-2-9b-it-q4f32_1-MLC',\n",
       "  'model_lib': 'https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_48/gemma-2-9b-it-q4f32_1-ctx4k_cs1k-webgpu.wasm',\n",
       "  'vram_required_MB': 8383.33,\n",
       "  'low_resource_required': False,\n",
       "  'overrides': {'context_window_size': 4096}},\n",
       " {'model': 'https://huggingface.co/mlc-ai/gemma-2-2b-jpn-it-q4f16_1-MLC',\n",
       "  'model_id': 'gemma-2-2b-jpn-it-q4f16_1-MLC',\n",
       "  'model_lib': 'https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_48/gemma-2-2b-jpn-it-q4f16_1-ctx4k_cs1k-webgpu.wasm',\n",
       "  'vram_required_MB': 1895.3,\n",
       "  'low_resource_required': True,\n",
       "  'required_features': ['shader-f16'],\n",
       "  'overrides': {'context_window_size': 4096}},\n",
       " {'model': 'https://huggingface.co/mlc-ai/gemma-2-2b-jpn-it-q4f32_1-MLC',\n",
       "  'model_id': 'gemma-2-2b-jpn-it-q4f32_1-MLC',\n",
       "  'model_lib': 'https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_48/gemma-2-2b-jpn-it-q4f32_1-ctx4k_cs1k-webgpu.wasm',\n",
       "  'vram_required_MB': 2508.75,\n",
       "  'low_resource_required': True,\n",
       "  'overrides': {'context_window_size': 4096}},\n",
       " {'model': 'https://huggingface.co/mlc-ai/Qwen2.5-0.5B-Instruct-q4f16_1-MLC',\n",
       "  'model_id': 'Qwen2.5-0.5B-Instruct-q4f16_1-MLC',\n",
       "  'model_lib': 'https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_48/Qwen2-0.5B-Instruct-q4f16_1-ctx4k_cs1k-webgpu.wasm',\n",
       "  'low_resource_required': True,\n",
       "  'vram_required_MB': 944.62,\n",
       "  'overrides': {'context_window_size': 4096}},\n",
       " {'model': 'https://huggingface.co/mlc-ai/Qwen2.5-0.5B-Instruct-q4f32_1-MLC',\n",
       "  'model_id': 'Qwen2.5-0.5B-Instruct-q4f32_1-MLC',\n",
       "  'model_lib': 'https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_48/Qwen2-0.5B-Instruct-q4f32_1-ctx4k_cs1k-webgpu.wasm',\n",
       "  'low_resource_required': True,\n",
       "  'vram_required_MB': 1060.2,\n",
       "  'overrides': {'context_window_size': 4096}},\n",
       " {'model': 'https://huggingface.co/mlc-ai/Qwen2.5-0.5B-Instruct-q0f16-MLC',\n",
       "  'model_id': 'Qwen2.5-0.5B-Instruct-q0f16-MLC',\n",
       "  'model_lib': 'https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_48/Qwen2-0.5B-Instruct-q0f16-ctx4k_cs1k-webgpu.wasm',\n",
       "  'low_resource_required': True,\n",
       "  'vram_required_MB': 1624.12,\n",
       "  'overrides': {'context_window_size': 4096}},\n",
       " {'model': 'https://huggingface.co/mlc-ai/Qwen2.5-0.5B-Instruct-q0f32-MLC',\n",
       "  'model_id': 'Qwen2.5-0.5B-Instruct-q0f32-MLC',\n",
       "  'model_lib': 'https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_48/Qwen2-0.5B-Instruct-q0f32-ctx4k_cs1k-webgpu.wasm',\n",
       "  'low_resource_required': True,\n",
       "  'vram_required_MB': 2654.75,\n",
       "  'overrides': {'context_window_size': 4096}},\n",
       " {'model': 'https://huggingface.co/mlc-ai/Qwen2.5-1.5B-Instruct-q4f16_1-MLC',\n",
       "  'model_id': 'Qwen2.5-1.5B-Instruct-q4f16_1-MLC',\n",
       "  'model_lib': 'https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_48/Qwen2-1.5B-Instruct-q4f16_1-ctx4k_cs1k-webgpu.wasm',\n",
       "  'low_resource_required': True,\n",
       "  'vram_required_MB': 1629.75,\n",
       "  'overrides': {'context_window_size': 4096}},\n",
       " {'model': 'https://huggingface.co/mlc-ai/Qwen2.5-1.5B-Instruct-q4f32_1-MLC',\n",
       "  'model_id': 'Qwen2.5-1.5B-Instruct-q4f32_1-MLC',\n",
       "  'model_lib': 'https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_48/Qwen2-1.5B-Instruct-q4f32_1-ctx4k_cs1k-webgpu.wasm',\n",
       "  'low_resource_required': True,\n",
       "  'vram_required_MB': 1888.97,\n",
       "  'overrides': {'context_window_size': 4096}},\n",
       " {'model': 'https://huggingface.co/mlc-ai/Qwen2.5-3B-Instruct-q4f16_1-MLC',\n",
       "  'model_id': 'Qwen2.5-3B-Instruct-q4f16_1-MLC',\n",
       "  'model_lib': 'https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_48/Qwen2.5-3B-Instruct-q4f16_1-ctx4k_cs1k-webgpu.wasm',\n",
       "  'low_resource_required': True,\n",
       "  'vram_required_MB': 2504.76,\n",
       "  'overrides': {'context_window_size': 4096}},\n",
       " {'model': 'https://huggingface.co/mlc-ai/Qwen2.5-3B-Instruct-q4f32_1-MLC',\n",
       "  'model_id': 'Qwen2.5-3B-Instruct-q4f32_1-MLC',\n",
       "  'model_lib': 'https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_48/Qwen2.5-3B-Instruct-q4f32_1-ctx4k_cs1k-webgpu.wasm',\n",
       "  'low_resource_required': True,\n",
       "  'vram_required_MB': 2893.64,\n",
       "  'overrides': {'context_window_size': 4096}},\n",
       " {'model': 'https://huggingface.co/mlc-ai/Qwen2.5-7B-Instruct-q4f16_1-MLC',\n",
       "  'model_id': 'Qwen2.5-7B-Instruct-q4f16_1-MLC',\n",
       "  'model_lib': 'https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_48/Qwen2-7B-Instruct-q4f16_1-ctx4k_cs1k-webgpu.wasm',\n",
       "  'low_resource_required': False,\n",
       "  'vram_required_MB': 5106.67,\n",
       "  'overrides': {'context_window_size': 4096}},\n",
       " {'model': 'https://huggingface.co/mlc-ai/Qwen2.5-7B-Instruct-q4f32_1-MLC',\n",
       "  'model_id': 'Qwen2.5-7B-Instruct-q4f32_1-MLC',\n",
       "  'model_lib': 'https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_48/Qwen2-7B-Instruct-q4f32_1-ctx4k_cs1k-webgpu.wasm',\n",
       "  'low_resource_required': False,\n",
       "  'vram_required_MB': 5900.09,\n",
       "  'overrides': {'context_window_size': 4096}},\n",
       " {'model': 'https://huggingface.co/mlc-ai/Qwen2.5-Coder-0.5B-Instruct-q4f16_1-MLC',\n",
       "  'model_id': 'Qwen2.5-Coder-0.5B-Instruct-q4f16_1-MLC',\n",
       "  'model_lib': 'https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_48/Qwen2-0.5B-Instruct-q4f16_1-ctx4k_cs1k-webgpu.wasm',\n",
       "  'low_resource_required': True,\n",
       "  'vram_required_MB': 944.62,\n",
       "  'overrides': {'context_window_size': 4096}},\n",
       " {'model': 'https://huggingface.co/mlc-ai/Qwen2.5-Coder-0.5B-Instruct-q4f32_1-MLC',\n",
       "  'model_id': 'Qwen2.5-Coder-0.5B-Instruct-q4f32_1-MLC',\n",
       "  'model_lib': 'https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_48/Qwen2-0.5B-Instruct-q4f32_1-ctx4k_cs1k-webgpu.wasm',\n",
       "  'low_resource_required': True,\n",
       "  'vram_required_MB': 1060.2,\n",
       "  'overrides': {'context_window_size': 4096}},\n",
       " {'model': 'https://huggingface.co/mlc-ai/Qwen2.5-Coder-0.5B-Instruct-q0f16-MLC',\n",
       "  'model_id': 'Qwen2.5-Coder-0.5B-Instruct-q0f16-MLC',\n",
       "  'model_lib': 'https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_48/Qwen2-0.5B-Instruct-q0f16-ctx4k_cs1k-webgpu.wasm',\n",
       "  'low_resource_required': True,\n",
       "  'vram_required_MB': 1624.12,\n",
       "  'overrides': {'context_window_size': 4096}},\n",
       " {'model': 'https://huggingface.co/mlc-ai/Qwen2.5-Coder-0.5B-Instruct-q0f32-MLC',\n",
       "  'model_id': 'Qwen2.5-Coder-0.5B-Instruct-q0f32-MLC',\n",
       "  'model_lib': 'https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_48/Qwen2-0.5B-Instruct-q0f32-ctx4k_cs1k-webgpu.wasm',\n",
       "  'low_resource_required': True,\n",
       "  'vram_required_MB': 2654.75,\n",
       "  'overrides': {'context_window_size': 4096}},\n",
       " {'model': 'https://huggingface.co/mlc-ai/Qwen2.5-Coder-1.5B-Instruct-q4f16_1-MLC',\n",
       "  'model_id': 'Qwen2.5-Coder-1.5B-Instruct-q4f16_1-MLC',\n",
       "  'model_lib': 'https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_48/Qwen2-1.5B-Instruct-q4f16_1-ctx4k_cs1k-webgpu.wasm',\n",
       "  'low_resource_required': False,\n",
       "  'vram_required_MB': 1629.75,\n",
       "  'overrides': {'context_window_size': 4096}},\n",
       " {'model': 'https://huggingface.co/mlc-ai/Qwen2.5-Coder-1.5B-Instruct-q4f32_1-MLC',\n",
       "  'model_id': 'Qwen2.5-Coder-1.5B-Instruct-q4f32_1-MLC',\n",
       "  'model_lib': 'https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_48/Qwen2-1.5B-Instruct-q4f32_1-ctx4k_cs1k-webgpu.wasm',\n",
       "  'low_resource_required': False,\n",
       "  'vram_required_MB': 1888.97,\n",
       "  'overrides': {'context_window_size': 4096}},\n",
       " {'model': 'https://huggingface.co/mlc-ai/Qwen2.5-Coder-3B-Instruct-q4f16_1-MLC',\n",
       "  'model_id': 'Qwen2.5-Coder-3B-Instruct-q4f16_1-MLC',\n",
       "  'model_lib': 'https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_48/Qwen2.5-3B-Instruct-q4f16_1-ctx4k_cs1k-webgpu.wasm',\n",
       "  'low_resource_required': True,\n",
       "  'vram_required_MB': 2504.76,\n",
       "  'overrides': {'context_window_size': 4096}},\n",
       " {'model': 'https://huggingface.co/mlc-ai/Qwen2.5-Coder-3B-Instruct-q4f32_1-MLC',\n",
       "  'model_id': 'Qwen2.5-Coder-3B-Instruct-q4f32_1-MLC',\n",
       "  'model_lib': 'https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_48/Qwen2.5-3B-Instruct-q4f32_1-ctx4k_cs1k-webgpu.wasm',\n",
       "  'low_resource_required': True,\n",
       "  'vram_required_MB': 2893.64,\n",
       "  'overrides': {'context_window_size': 4096}},\n",
       " {'model': 'https://huggingface.co/mlc-ai/Qwen2.5-Coder-7B-Instruct-q4f16_1-MLC',\n",
       "  'model_id': 'Qwen2.5-Coder-7B-Instruct-q4f16_1-MLC',\n",
       "  'model_lib': 'https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_48/Qwen2-7B-Instruct-q4f16_1-ctx4k_cs1k-webgpu.wasm',\n",
       "  'low_resource_required': False,\n",
       "  'vram_required_MB': 5106.67,\n",
       "  'overrides': {'context_window_size': 4096}},\n",
       " {'model': 'https://huggingface.co/mlc-ai/Qwen2.5-Coder-7B-Instruct-q4f32_1-MLC',\n",
       "  'model_id': 'Qwen2.5-Coder-7B-Instruct-q4f32_1-MLC',\n",
       "  'model_lib': 'https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_48/Qwen2-7B-Instruct-q4f32_1-ctx4k_cs1k-webgpu.wasm',\n",
       "  'low_resource_required': False,\n",
       "  'vram_required_MB': 5900.09,\n",
       "  'overrides': {'context_window_size': 4096}},\n",
       " {'model': 'https://huggingface.co/mlc-ai/Qwen2.5-Math-1.5B-Instruct-q4f16_1-MLC',\n",
       "  'model_id': 'Qwen2.5-Math-1.5B-Instruct-q4f16_1-MLC',\n",
       "  'model_lib': 'https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_48/Qwen2-1.5B-Instruct-q4f16_1-ctx4k_cs1k-webgpu.wasm',\n",
       "  'low_resource_required': True,\n",
       "  'vram_required_MB': 1629.75,\n",
       "  'overrides': {'context_window_size': 4096}},\n",
       " {'model': 'https://huggingface.co/mlc-ai/Qwen2.5-Math-1.5B-Instruct-q4f32_1-MLC',\n",
       "  'model_id': 'Qwen2.5-Math-1.5B-Instruct-q4f32_1-MLC',\n",
       "  'model_lib': 'https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_48/Qwen2-1.5B-Instruct-q4f32_1-ctx4k_cs1k-webgpu.wasm',\n",
       "  'low_resource_required': True,\n",
       "  'vram_required_MB': 1888.97,\n",
       "  'overrides': {'context_window_size': 4096}},\n",
       " {'model': 'https://huggingface.co/mlc-ai/stablelm-2-zephyr-1_6b-q4f16_1-MLC',\n",
       "  'model_id': 'stablelm-2-zephyr-1_6b-q4f16_1-MLC',\n",
       "  'model_lib': 'https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_48/stablelm-2-zephyr-1_6b-q4f16_1-ctx4k_cs1k-webgpu.wasm',\n",
       "  'vram_required_MB': 2087.66,\n",
       "  'low_resource_required': False,\n",
       "  'overrides': {'context_window_size': 4096}},\n",
       " {'model': 'https://huggingface.co/mlc-ai/stablelm-2-zephyr-1_6b-q4f32_1-MLC',\n",
       "  'model_id': 'stablelm-2-zephyr-1_6b-q4f32_1-MLC',\n",
       "  'model_lib': 'https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_48/stablelm-2-zephyr-1_6b-q4f32_1-ctx4k_cs1k-webgpu.wasm',\n",
       "  'vram_required_MB': 2999.33,\n",
       "  'low_resource_required': False,\n",
       "  'overrides': {'context_window_size': 4096}},\n",
       " {'model': 'https://huggingface.co/mlc-ai/stablelm-2-zephyr-1_6b-q4f16_1-MLC',\n",
       "  'model_id': 'stablelm-2-zephyr-1_6b-q4f16_1-MLC-1k',\n",
       "  'model_lib': 'https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_48/stablelm-2-zephyr-1_6b-q4f16_1-ctx4k_cs1k-webgpu.wasm',\n",
       "  'vram_required_MB': 1511.66,\n",
       "  'low_resource_required': True,\n",
       "  'overrides': {'context_window_size': 1024}},\n",
       " {'model': 'https://huggingface.co/mlc-ai/stablelm-2-zephyr-1_6b-q4f32_1-MLC',\n",
       "  'model_id': 'stablelm-2-zephyr-1_6b-q4f32_1-MLC-1k',\n",
       "  'model_lib': 'https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_48/stablelm-2-zephyr-1_6b-q4f32_1-ctx4k_cs1k-webgpu.wasm',\n",
       "  'vram_required_MB': 1847.33,\n",
       "  'low_resource_required': True,\n",
       "  'overrides': {'context_window_size': 1024}},\n",
       " {'model': 'https://huggingface.co/mlc-ai/RedPajama-INCITE-Chat-3B-v1-q4f16_1-MLC',\n",
       "  'model_id': 'RedPajama-INCITE-Chat-3B-v1-q4f16_1-MLC',\n",
       "  'model_lib': 'https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_48/RedPajama-INCITE-Chat-3B-v1-q4f16_1-ctx2k_cs1k-webgpu.wasm',\n",
       "  'vram_required_MB': 2972.09,\n",
       "  'low_resource_required': False,\n",
       "  'required_features': ['shader-f16'],\n",
       "  'overrides': {'context_window_size': 2048}},\n",
       " {'model': 'https://huggingface.co/mlc-ai/RedPajama-INCITE-Chat-3B-v1-q4f32_1-MLC',\n",
       "  'model_id': 'RedPajama-INCITE-Chat-3B-v1-q4f32_1-MLC',\n",
       "  'model_lib': 'https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_48/RedPajama-INCITE-Chat-3B-v1-q4f32_1-ctx2k_cs1k-webgpu.wasm',\n",
       "  'vram_required_MB': 3928.09,\n",
       "  'low_resource_required': False,\n",
       "  'overrides': {'context_window_size': 2048}},\n",
       " {'model': 'https://huggingface.co/mlc-ai/RedPajama-INCITE-Chat-3B-v1-q4f16_1-MLC',\n",
       "  'model_id': 'RedPajama-INCITE-Chat-3B-v1-q4f16_1-MLC-1k',\n",
       "  'model_lib': 'https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_48/RedPajama-INCITE-Chat-3B-v1-q4f16_1-ctx2k_cs1k-webgpu.wasm',\n",
       "  'vram_required_MB': 2041.09,\n",
       "  'low_resource_required': True,\n",
       "  'required_features': ['shader-f16'],\n",
       "  'overrides': {'context_window_size': 1024}},\n",
       " {'model': 'https://huggingface.co/mlc-ai/RedPajama-INCITE-Chat-3B-v1-q4f32_1-MLC',\n",
       "  'model_id': 'RedPajama-INCITE-Chat-3B-v1-q4f32_1-MLC-1k',\n",
       "  'model_lib': 'https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_48/RedPajama-INCITE-Chat-3B-v1-q4f32_1-ctx2k_cs1k-webgpu.wasm',\n",
       "  'vram_required_MB': 2558.09,\n",
       "  'low_resource_required': True,\n",
       "  'overrides': {'context_window_size': 1024}},\n",
       " {'model': 'https://huggingface.co/mlc-ai/TinyLlama-1.1B-Chat-v1.0-q4f16_1-MLC',\n",
       "  'model_id': 'TinyLlama-1.1B-Chat-v1.0-q4f16_1-MLC',\n",
       "  'model_lib': 'https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_48/TinyLlama-1.1B-Chat-v1.0-q4f16_1-ctx2k_cs1k-webgpu.wasm',\n",
       "  'vram_required_MB': 697.24,\n",
       "  'low_resource_required': True,\n",
       "  'required_features': ['shader-f16'],\n",
       "  'overrides': {'context_window_size': 2048}},\n",
       " {'model': 'https://huggingface.co/mlc-ai/TinyLlama-1.1B-Chat-v1.0-q4f32_1-MLC',\n",
       "  'model_id': 'TinyLlama-1.1B-Chat-v1.0-q4f32_1-MLC',\n",
       "  'model_lib': 'https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_48/TinyLlama-1.1B-Chat-v1.0-q4f32_1-ctx2k_cs1k-webgpu.wasm',\n",
       "  'vram_required_MB': 839.98,\n",
       "  'low_resource_required': True,\n",
       "  'overrides': {'context_window_size': 2048}},\n",
       " {'model': 'https://huggingface.co/mlc-ai/TinyLlama-1.1B-Chat-v1.0-q4f16_1-MLC',\n",
       "  'model_id': 'TinyLlama-1.1B-Chat-v1.0-q4f16_1-MLC-1k',\n",
       "  'model_lib': 'https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_48/TinyLlama-1.1B-Chat-v1.0-q4f16_1-ctx2k_cs1k-webgpu.wasm',\n",
       "  'vram_required_MB': 675.24,\n",
       "  'low_resource_required': True,\n",
       "  'required_features': ['shader-f16'],\n",
       "  'overrides': {'context_window_size': 1024}},\n",
       " {'model': 'https://huggingface.co/mlc-ai/TinyLlama-1.1B-Chat-v1.0-q4f32_1-MLC',\n",
       "  'model_id': 'TinyLlama-1.1B-Chat-v1.0-q4f32_1-MLC-1k',\n",
       "  'model_lib': 'https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_48/TinyLlama-1.1B-Chat-v1.0-q4f32_1-ctx2k_cs1k-webgpu.wasm',\n",
       "  'vram_required_MB': 795.98,\n",
       "  'low_resource_required': True,\n",
       "  'overrides': {'context_window_size': 1024}},\n",
       " {'model': 'https://huggingface.co/mlc-ai/Llama-3.1-70B-Instruct-q3f16_1-MLC',\n",
       "  'model_id': 'Llama-3.1-70B-Instruct-q3f16_1-MLC',\n",
       "  'model_lib': 'https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_48/Llama-3_1-70B-Instruct-q3f16_1-ctx4k_cs1k-webgpu.wasm',\n",
       "  'vram_required_MB': 31153.13,\n",
       "  'low_resource_required': False,\n",
       "  'overrides': {'context_window_size': 4096}},\n",
       " {'model': 'https://huggingface.co/mlc-ai/Qwen2-0.5B-Instruct-q4f16_1-MLC',\n",
       "  'model_id': 'Qwen2-0.5B-Instruct-q4f16_1-MLC',\n",
       "  'model_lib': 'https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_48/Qwen2-0.5B-Instruct-q4f16_1-ctx4k_cs1k-webgpu.wasm',\n",
       "  'low_resource_required': True,\n",
       "  'vram_required_MB': 944.62,\n",
       "  'overrides': {'context_window_size': 4096}},\n",
       " {'model': 'https://huggingface.co/mlc-ai/Qwen2-0.5B-Instruct-q0f16-MLC',\n",
       "  'model_id': 'Qwen2-0.5B-Instruct-q0f16-MLC',\n",
       "  'model_lib': 'https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_48/Qwen2-0.5B-Instruct-q0f16-ctx4k_cs1k-webgpu.wasm',\n",
       "  'low_resource_required': True,\n",
       "  'vram_required_MB': 1624.12,\n",
       "  'overrides': {'context_window_size': 4096}},\n",
       " {'model': 'https://huggingface.co/mlc-ai/Qwen2-0.5B-Instruct-q0f32-MLC',\n",
       "  'model_id': 'Qwen2-0.5B-Instruct-q0f32-MLC',\n",
       "  'model_lib': 'https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_48/Qwen2-0.5B-Instruct-q0f32-ctx4k_cs1k-webgpu.wasm',\n",
       "  'low_resource_required': True,\n",
       "  'vram_required_MB': 2654.75,\n",
       "  'overrides': {'context_window_size': 4096}},\n",
       " {'model': 'https://huggingface.co/mlc-ai/Qwen2-1.5B-Instruct-q4f16_1-MLC',\n",
       "  'model_id': 'Qwen2-1.5B-Instruct-q4f16_1-MLC',\n",
       "  'model_lib': 'https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_48/Qwen2-1.5B-Instruct-q4f16_1-ctx4k_cs1k-webgpu.wasm',\n",
       "  'low_resource_required': True,\n",
       "  'vram_required_MB': 1629.75,\n",
       "  'overrides': {'context_window_size': 4096}},\n",
       " {'model': 'https://huggingface.co/mlc-ai/Qwen2-1.5B-Instruct-q4f32_1-MLC',\n",
       "  'model_id': 'Qwen2-1.5B-Instruct-q4f32_1-MLC',\n",
       "  'model_lib': 'https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_48/Qwen2-1.5B-Instruct-q4f32_1-ctx4k_cs1k-webgpu.wasm',\n",
       "  'low_resource_required': True,\n",
       "  'vram_required_MB': 1888.97,\n",
       "  'overrides': {'context_window_size': 4096}},\n",
       " {'model': 'https://huggingface.co/mlc-ai/Qwen2-7B-Instruct-q4f16_1-MLC',\n",
       "  'model_id': 'Qwen2-7B-Instruct-q4f16_1-MLC',\n",
       "  'model_lib': 'https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_48/Qwen2-7B-Instruct-q4f16_1-ctx4k_cs1k-webgpu.wasm',\n",
       "  'low_resource_required': False,\n",
       "  'vram_required_MB': 5106.67,\n",
       "  'overrides': {'context_window_size': 4096}},\n",
       " {'model': 'https://huggingface.co/mlc-ai/Qwen2-7B-Instruct-q4f32_1-MLC',\n",
       "  'model_id': 'Qwen2-7B-Instruct-q4f32_1-MLC',\n",
       "  'model_lib': 'https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_48/Qwen2-7B-Instruct-q4f32_1-ctx4k_cs1k-webgpu.wasm',\n",
       "  'low_resource_required': False,\n",
       "  'vram_required_MB': 5900.09,\n",
       "  'overrides': {'context_window_size': 4096}},\n",
       " {'model': 'https://huggingface.co/mlc-ai/Qwen2-Math-1.5B-Instruct-q4f16_1-MLC',\n",
       "  'model_id': 'Qwen2-Math-1.5B-Instruct-q4f16_1-MLC',\n",
       "  'model_lib': 'https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_48/Qwen2-1.5B-Instruct-q4f16_1-ctx4k_cs1k-webgpu.wasm',\n",
       "  'low_resource_required': True,\n",
       "  'vram_required_MB': 1629.75,\n",
       "  'overrides': {'context_window_size': 4096}},\n",
       " {'model': 'https://huggingface.co/mlc-ai/Qwen2-Math-1.5B-Instruct-q4f32_1-MLC',\n",
       "  'model_id': 'Qwen2-Math-1.5B-Instruct-q4f32_1-MLC',\n",
       "  'model_lib': 'https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_48/Qwen2-1.5B-Instruct-q4f32_1-ctx4k_cs1k-webgpu.wasm',\n",
       "  'low_resource_required': True,\n",
       "  'vram_required_MB': 1888.97,\n",
       "  'overrides': {'context_window_size': 4096}},\n",
       " {'model': 'https://huggingface.co/mlc-ai/Qwen2-Math-7B-Instruct-q4f16_1-MLC',\n",
       "  'model_id': 'Qwen2-Math-7B-Instruct-q4f16_1-MLC',\n",
       "  'model_lib': 'https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_48/Qwen2-7B-Instruct-q4f16_1-ctx4k_cs1k-webgpu.wasm',\n",
       "  'low_resource_required': False,\n",
       "  'vram_required_MB': 5106.67,\n",
       "  'overrides': {'context_window_size': 4096}},\n",
       " {'model': 'https://huggingface.co/mlc-ai/Qwen2-Math-7B-Instruct-q4f32_1-MLC',\n",
       "  'model_id': 'Qwen2-Math-7B-Instruct-q4f32_1-MLC',\n",
       "  'model_lib': 'https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_48/Qwen2-7B-Instruct-q4f32_1-ctx4k_cs1k-webgpu.wasm',\n",
       "  'low_resource_required': False,\n",
       "  'vram_required_MB': 5900.09,\n",
       "  'overrides': {'context_window_size': 4096}},\n",
       " {'model': 'https://huggingface.co/mlc-ai/Llama-3-8B-Instruct-q4f32_1-MLC',\n",
       "  'model_id': 'Llama-3-8B-Instruct-q4f32_1-MLC-1k',\n",
       "  'model_lib': 'https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_48/Llama-3-8B-Instruct-q4f32_1-ctx4k_cs1k-webgpu.wasm',\n",
       "  'vram_required_MB': 5295.7,\n",
       "  'low_resource_required': True,\n",
       "  'overrides': {'context_window_size': 1024}},\n",
       " {'model': 'https://huggingface.co/mlc-ai/Llama-3-8B-Instruct-q4f16_1-MLC',\n",
       "  'model_id': 'Llama-3-8B-Instruct-q4f16_1-MLC-1k',\n",
       "  'model_lib': 'https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_48/Llama-3-8B-Instruct-q4f16_1-ctx4k_cs1k-webgpu.wasm',\n",
       "  'vram_required_MB': 4598.34,\n",
       "  'low_resource_required': True,\n",
       "  'overrides': {'context_window_size': 1024}},\n",
       " {'model': 'https://huggingface.co/mlc-ai/Llama-3-8B-Instruct-q4f32_1-MLC',\n",
       "  'model_id': 'Llama-3-8B-Instruct-q4f32_1-MLC',\n",
       "  'model_lib': 'https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_48/Llama-3-8B-Instruct-q4f32_1-ctx4k_cs1k-webgpu.wasm',\n",
       "  'vram_required_MB': 6101.01,\n",
       "  'low_resource_required': False,\n",
       "  'overrides': {'context_window_size': 4096}},\n",
       " {'model': 'https://huggingface.co/mlc-ai/Llama-3-8B-Instruct-q4f16_1-MLC',\n",
       "  'model_id': 'Llama-3-8B-Instruct-q4f16_1-MLC',\n",
       "  'model_lib': 'https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_48/Llama-3-8B-Instruct-q4f16_1-ctx4k_cs1k-webgpu.wasm',\n",
       "  'vram_required_MB': 5001,\n",
       "  'low_resource_required': False,\n",
       "  'overrides': {'context_window_size': 4096}},\n",
       " {'model': 'https://huggingface.co/mlc-ai/Llama-3-70B-Instruct-q3f16_1-MLC',\n",
       "  'model_id': 'Llama-3-70B-Instruct-q3f16_1-MLC',\n",
       "  'model_lib': 'https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_48/Llama-3-70B-Instruct-q3f16_1-ctx4k_cs1k-webgpu.wasm',\n",
       "  'vram_required_MB': 31153.13,\n",
       "  'low_resource_required': False,\n",
       "  'overrides': {'context_window_size': 4096}},\n",
       " {'model': 'https://huggingface.co/mlc-ai/Phi-3-mini-4k-instruct-q4f16_1-MLC',\n",
       "  'model_id': 'Phi-3-mini-4k-instruct-q4f16_1-MLC',\n",
       "  'model_lib': 'https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_48/Phi-3-mini-4k-instruct-q4f16_1-ctx4k_cs1k-webgpu.wasm',\n",
       "  'vram_required_MB': 3672.07,\n",
       "  'low_resource_required': False,\n",
       "  'overrides': {'context_window_size': 4096}},\n",
       " {'model': 'https://huggingface.co/mlc-ai/Phi-3-mini-4k-instruct-q4f32_1-MLC',\n",
       "  'model_id': 'Phi-3-mini-4k-instruct-q4f32_1-MLC',\n",
       "  'model_lib': 'https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_48/Phi-3-mini-4k-instruct-q4f32_1-ctx4k_cs1k-webgpu.wasm',\n",
       "  'vram_required_MB': 5483.12,\n",
       "  'low_resource_required': False,\n",
       "  'overrides': {'context_window_size': 4096}},\n",
       " {'model': 'https://huggingface.co/mlc-ai/Phi-3-mini-4k-instruct-q4f16_1-MLC',\n",
       "  'model_id': 'Phi-3-mini-4k-instruct-q4f16_1-MLC-1k',\n",
       "  'model_lib': 'https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_48/Phi-3-mini-4k-instruct-q4f16_1-ctx4k_cs1k-webgpu.wasm',\n",
       "  'vram_required_MB': 2520.07,\n",
       "  'low_resource_required': True,\n",
       "  'overrides': {'context_window_size': 1024}},\n",
       " {'model': 'https://huggingface.co/mlc-ai/Phi-3-mini-4k-instruct-q4f32_1-MLC',\n",
       "  'model_id': 'Phi-3-mini-4k-instruct-q4f32_1-MLC-1k',\n",
       "  'model_lib': 'https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_48/Phi-3-mini-4k-instruct-q4f32_1-ctx4k_cs1k-webgpu.wasm',\n",
       "  'vram_required_MB': 3179.12,\n",
       "  'low_resource_required': True,\n",
       "  'overrides': {'context_window_size': 1024}},\n",
       " {'model': 'https://huggingface.co/mlc-ai/Llama-2-7b-chat-hf-q4f32_1-MLC',\n",
       "  'model_id': 'Llama-2-7b-chat-hf-q4f32_1-MLC-1k',\n",
       "  'model_lib': 'https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_48/Llama-2-7b-chat-hf-q4f32_1-ctx4k_cs1k-webgpu.wasm',\n",
       "  'vram_required_MB': 5284.01,\n",
       "  'low_resource_required': False,\n",
       "  'overrides': {'context_window_size': 1024}},\n",
       " {'model': 'https://huggingface.co/mlc-ai/Llama-2-7b-chat-hf-q4f16_1-MLC',\n",
       "  'model_id': 'Llama-2-7b-chat-hf-q4f16_1-MLC-1k',\n",
       "  'model_lib': 'https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_48/Llama-2-7b-chat-hf-q4f16_1-ctx4k_cs1k-webgpu.wasm',\n",
       "  'vram_required_MB': 4618.52,\n",
       "  'low_resource_required': False,\n",
       "  'required_features': ['shader-f16'],\n",
       "  'overrides': {'context_window_size': 1024}},\n",
       " {'model': 'https://huggingface.co/mlc-ai/Llama-2-7b-chat-hf-q4f32_1-MLC',\n",
       "  'model_id': 'Llama-2-7b-chat-hf-q4f32_1-MLC',\n",
       "  'model_lib': 'https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_48/Llama-2-7b-chat-hf-q4f32_1-ctx4k_cs1k-webgpu.wasm',\n",
       "  'vram_required_MB': 9109.03,\n",
       "  'low_resource_required': False,\n",
       "  'overrides': {'context_window_size': 4096}},\n",
       " {'model': 'https://huggingface.co/mlc-ai/Llama-2-7b-chat-hf-q4f16_1-MLC',\n",
       "  'model_id': 'Llama-2-7b-chat-hf-q4f16_1-MLC',\n",
       "  'model_lib': 'https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_48/Llama-2-7b-chat-hf-q4f16_1-ctx4k_cs1k-webgpu.wasm',\n",
       "  'vram_required_MB': 6749.02,\n",
       "  'low_resource_required': False,\n",
       "  'required_features': ['shader-f16'],\n",
       "  'overrides': {'context_window_size': 4096}},\n",
       " {'model': 'https://huggingface.co/mlc-ai/Llama-2-13b-chat-hf-q4f16_1-MLC',\n",
       "  'model_id': 'Llama-2-13b-chat-hf-q4f16_1-MLC',\n",
       "  'model_lib': 'https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_48/Llama-2-13b-chat-hf-q4f16_1-ctx4k_cs1k-webgpu.wasm',\n",
       "  'vram_required_MB': 11814.09,\n",
       "  'low_resource_required': False,\n",
       "  'required_features': ['shader-f16'],\n",
       "  'overrides': {'context_window_size': 4096}},\n",
       " {'model': 'https://huggingface.co/mlc-ai/gemma-2b-it-q4f16_1-MLC',\n",
       "  'model_id': 'gemma-2b-it-q4f16_1-MLC',\n",
       "  'model_lib': 'https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_48/gemma-2b-it-q4f16_1-ctx4k_cs1k-webgpu.wasm',\n",
       "  'vram_required_MB': 1476.52,\n",
       "  'low_resource_required': False,\n",
       "  'buffer_size_required_bytes': 262144000,\n",
       "  'required_features': ['shader-f16'],\n",
       "  'overrides': {'context_window_size': 4096}},\n",
       " {'model': 'https://huggingface.co/mlc-ai/gemma-2b-it-q4f32_1-MLC',\n",
       "  'model_id': 'gemma-2b-it-q4f32_1-MLC',\n",
       "  'model_lib': 'https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_48/gemma-2b-it-q4f32_1-ctx4k_cs1k-webgpu.wasm',\n",
       "  'vram_required_MB': 1750.66,\n",
       "  'low_resource_required': False,\n",
       "  'buffer_size_required_bytes': 262144000,\n",
       "  'overrides': {'context_window_size': 4096}},\n",
       " {'model': 'https://huggingface.co/mlc-ai/gemma-2b-it-q4f16_1-MLC',\n",
       "  'model_id': 'gemma-2b-it-q4f16_1-MLC-1k',\n",
       "  'model_lib': 'https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_48/gemma-2b-it-q4f16_1-ctx4k_cs1k-webgpu.wasm',\n",
       "  'vram_required_MB': 1476.52,\n",
       "  'low_resource_required': True,\n",
       "  'buffer_size_required_bytes': 262144000,\n",
       "  'required_features': ['shader-f16'],\n",
       "  'overrides': {'context_window_size': 1024}},\n",
       " {'model': 'https://huggingface.co/mlc-ai/gemma-2b-it-q4f32_1-MLC',\n",
       "  'model_id': 'gemma-2b-it-q4f32_1-MLC-1k',\n",
       "  'model_lib': 'https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_48/gemma-2b-it-q4f32_1-ctx4k_cs1k-webgpu.wasm',\n",
       "  'vram_required_MB': 1750.66,\n",
       "  'low_resource_required': True,\n",
       "  'buffer_size_required_bytes': 262144000,\n",
       "  'overrides': {'context_window_size': 1024}},\n",
       " {'model': 'https://huggingface.co/mlc-ai/phi-2-q4f16_1-MLC',\n",
       "  'model_id': 'phi-2-q4f16_1-MLC',\n",
       "  'model_lib': 'https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_48/phi-2-q4f16_1-ctx2k_cs1k-webgpu.wasm',\n",
       "  'vram_required_MB': 3053.97,\n",
       "  'low_resource_required': False,\n",
       "  'required_features': ['shader-f16'],\n",
       "  'overrides': {'context_window_size': 2048}},\n",
       " {'model': 'https://huggingface.co/mlc-ai/phi-2-q4f32_1-MLC',\n",
       "  'model_id': 'phi-2-q4f32_1-MLC',\n",
       "  'model_lib': 'https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_48/phi-2-q4f32_1-ctx2k_cs1k-webgpu.wasm',\n",
       "  'vram_required_MB': 4032.48,\n",
       "  'low_resource_required': False,\n",
       "  'overrides': {'context_window_size': 2048}},\n",
       " {'model': 'https://huggingface.co/mlc-ai/phi-2-q4f16_1-MLC',\n",
       "  'model_id': 'phi-2-q4f16_1-MLC-1k',\n",
       "  'model_lib': 'https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_48/phi-2-q4f16_1-ctx2k_cs1k-webgpu.wasm',\n",
       "  'vram_required_MB': 2131.97,\n",
       "  'low_resource_required': True,\n",
       "  'required_features': ['shader-f16'],\n",
       "  'overrides': {'context_window_size': 1024}},\n",
       " {'model': 'https://huggingface.co/mlc-ai/phi-2-q4f32_1-MLC',\n",
       "  'model_id': 'phi-2-q4f32_1-MLC-1k',\n",
       "  'model_lib': 'https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_48/phi-2-q4f32_1-ctx2k_cs1k-webgpu.wasm',\n",
       "  'vram_required_MB': 2740.48,\n",
       "  'low_resource_required': True,\n",
       "  'overrides': {'context_window_size': 1024}},\n",
       " {'model': 'https://huggingface.co/mlc-ai/phi-1_5-q4f16_1-MLC',\n",
       "  'model_id': 'phi-1_5-q4f16_1-MLC',\n",
       "  'model_lib': 'https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_48/phi-1_5-q4f16_1-ctx2k_cs1k-webgpu.wasm',\n",
       "  'vram_required_MB': 1210.09,\n",
       "  'low_resource_required': True,\n",
       "  'required_features': ['shader-f16'],\n",
       "  'overrides': {'context_window_size': 2048}},\n",
       " {'model': 'https://huggingface.co/mlc-ai/phi-1_5-q4f32_1-MLC',\n",
       "  'model_id': 'phi-1_5-q4f32_1-MLC',\n",
       "  'model_lib': 'https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_48/phi-1_5-q4f32_1-ctx2k_cs1k-webgpu.wasm',\n",
       "  'vram_required_MB': 1682.09,\n",
       "  'low_resource_required': True,\n",
       "  'overrides': {'context_window_size': 2048}},\n",
       " {'model': 'https://huggingface.co/mlc-ai/phi-1_5-q4f16_1-MLC',\n",
       "  'model_id': 'phi-1_5-q4f16_1-MLC-1k',\n",
       "  'model_lib': 'https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_48/phi-1_5-q4f16_1-ctx2k_cs1k-webgpu.wasm',\n",
       "  'vram_required_MB': 1210.09,\n",
       "  'low_resource_required': True,\n",
       "  'required_features': ['shader-f16'],\n",
       "  'overrides': {'context_window_size': 1024}},\n",
       " {'model': 'https://huggingface.co/mlc-ai/phi-1_5-q4f32_1-MLC',\n",
       "  'model_id': 'phi-1_5-q4f32_1-MLC-1k',\n",
       "  'model_lib': 'https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_48/phi-1_5-q4f32_1-ctx2k_cs1k-webgpu.wasm',\n",
       "  'vram_required_MB': 1682.09,\n",
       "  'low_resource_required': True,\n",
       "  'overrides': {'context_window_size': 1024}},\n",
       " {'model': 'https://huggingface.co/mlc-ai/TinyLlama-1.1B-Chat-v0.4-q4f16_1-MLC',\n",
       "  'model_id': 'TinyLlama-1.1B-Chat-v0.4-q4f16_1-MLC',\n",
       "  'model_lib': 'https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_48/TinyLlama-1.1B-Chat-v0.4-q4f16_1-ctx2k_cs1k-webgpu.wasm',\n",
       "  'vram_required_MB': 697.24,\n",
       "  'low_resource_required': True,\n",
       "  'required_features': ['shader-f16'],\n",
       "  'overrides': {'context_window_size': 2048}},\n",
       " {'model': 'https://huggingface.co/mlc-ai/TinyLlama-1.1B-Chat-v0.4-q4f32_1-MLC',\n",
       "  'model_id': 'TinyLlama-1.1B-Chat-v0.4-q4f32_1-MLC',\n",
       "  'model_lib': 'https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_48/TinyLlama-1.1B-Chat-v0.4-q4f32_1-ctx2k_cs1k-webgpu.wasm',\n",
       "  'vram_required_MB': 839.98,\n",
       "  'low_resource_required': True,\n",
       "  'overrides': {'context_window_size': 2048}},\n",
       " {'model': 'https://huggingface.co/mlc-ai/TinyLlama-1.1B-Chat-v0.4-q4f16_1-MLC',\n",
       "  'model_id': 'TinyLlama-1.1B-Chat-v0.4-q4f16_1-MLC-1k',\n",
       "  'model_lib': 'https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_48/TinyLlama-1.1B-Chat-v0.4-q4f16_1-ctx2k_cs1k-webgpu.wasm',\n",
       "  'vram_required_MB': 675.24,\n",
       "  'low_resource_required': True,\n",
       "  'required_features': ['shader-f16'],\n",
       "  'overrides': {'context_window_size': 1024}},\n",
       " {'model': 'https://huggingface.co/mlc-ai/TinyLlama-1.1B-Chat-v0.4-q4f32_1-MLC',\n",
       "  'model_id': 'TinyLlama-1.1B-Chat-v0.4-q4f32_1-MLC-1k',\n",
       "  'model_lib': 'https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_48/TinyLlama-1.1B-Chat-v0.4-q4f32_1-ctx2k_cs1k-webgpu.wasm',\n",
       "  'vram_required_MB': 795.98,\n",
       "  'low_resource_required': True,\n",
       "  'overrides': {'context_window_size': 1024}},\n",
       " {'model': 'https://huggingface.co/mlc-ai/snowflake-arctic-embed-m-q0f32-MLC',\n",
       "  'model_id': 'snowflake-arctic-embed-m-q0f32-MLC-b32',\n",
       "  'model_lib': 'https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_48/snowflake-arctic-embed-m-q0f32-ctx512_cs512_batch32-webgpu.wasm',\n",
       "  'vram_required_MB': 1407.51,\n",
       "  'model_type': 1},\n",
       " {'model': 'https://huggingface.co/mlc-ai/snowflake-arctic-embed-m-q0f32-MLC',\n",
       "  'model_id': 'snowflake-arctic-embed-m-q0f32-MLC-b4',\n",
       "  'model_lib': 'https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_48/snowflake-arctic-embed-m-q0f32-ctx512_cs512_batch4-webgpu.wasm',\n",
       "  'vram_required_MB': 539.4,\n",
       "  'model_type': 1},\n",
       " {'model': 'https://huggingface.co/mlc-ai/snowflake-arctic-embed-s-q0f32-MLC',\n",
       "  'model_id': 'snowflake-arctic-embed-s-q0f32-MLC-b32',\n",
       "  'model_lib': 'https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_48/snowflake-arctic-embed-s-q0f32-ctx512_cs512_batch32-webgpu.wasm',\n",
       "  'vram_required_MB': 1022.82,\n",
       "  'model_type': 1},\n",
       " {'model': 'https://huggingface.co/mlc-ai/snowflake-arctic-embed-s-q0f32-MLC',\n",
       "  'model_id': 'snowflake-arctic-embed-s-q0f32-MLC-b4',\n",
       "  'model_lib': 'https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_48/snowflake-arctic-embed-s-q0f32-ctx512_cs512_batch4-webgpu.wasm',\n",
       "  'vram_required_MB': 238.71,\n",
       "  'model_type': 1}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display models\n",
    "w.models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In the quiet, moonlit night,\\nA whisper of love, so bright.\\nUnder the starlit sky so blue,\\nA tale of dreams, forever true.'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = w.convert(\"Write me a four line poem\")\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Non-blocking\n",
    "w.base_convert(\"Write me a 125 word short story\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'working on it...',\n",
       " 'output_template': '',\n",
       " 'input_raw': 'Write me a 125 word short story'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# When it's ready, collect from:\n",
    "w.response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'completed',\n",
       " 'output_raw': 'Once upon a time, in a bustling city, there lived a little kitten named Luna. She was the most curious kitten ever, with eyes that sparkled like stars and fur as soft as the moon. Luna had a big dream: to explore the whole world and discover its secrets. One day, she decided to take the leap and embarked on an adventure.\\n\\nLuna\\'s journey took her through cobweb-filled alleyways, past towering skyscrapers, and over busy roads. Along the way, she met many creatures who shared their stories with her. There was Benny the brave bear, who taught her how to stand tall like him; Dr. Doodlebug the wise old bug, who showed her how to navigate through tight spaces; and Sally Squirrel, whose bushy tail swung back and forth as she explained about hidden stashes of nuts.\\n\\nDespite facing many challenges such as slipping on wet leaves and getting lost in narrow alleys, Luna never gave up. She remembered Benny\\'s advice: \"Stand tall like me,\" she repeated to herself each time she slipped on wet leaves or felt scared about being alone at night. She also kept Dr. Doodlebug\\'s lesson in mind: \"Navigating through tight spaces is not about getting stuck.\" And Sally Squirrel\\'s secret stash reminded her always to have something safe when things got tough: \"There\\'s always a nut for rainy days.\"\\n\\nFinally, after weeks of adventures and lessons learned from friends around town, Luna reached her dream destination – an old but beautiful lighthouse standing high above the sea waves on a rocky cliffside overlooking the vast ocean below. As she climbed up the winding stairs one by one with each step feeling like climbing into history itself, she realized that no matter how big or small you are or where you come from, everyone has their own unique story worth sharing because we all have our own special place in this world called home – right next to this lighthouse which stood tall even against strong winds and heavy rains for centuries without losing its light during nights when it seemed darkest outside.',\n",
       " 'max_tokens': 512,\n",
       " 'temperature': 0.5,\n",
       " 'top_p': 0.5,\n",
       " 'frequency_penalty': 0.5,\n",
       " 'presence_penalty': 0.3}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "w.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the model with a status display\n",
    "\n",
    "We can also run the model with either an embedded, or a sidebar panel, display."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jupyter_anywidget_webllm import webllm_panel, webllm_inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93993a2936924a3c9a813b0bde180fa5",
       "version_major": 2,
       "version_minor": 1
      },
      "text/plain": [
       "webllmWidget(response={'status': 'initialising'})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "w_inline = webllm_inline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_panel = webllm_panel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structured output\n",
    "\n",
    "We can generate a structured output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_template=\"\"\"{\n",
    "    \"title\": \"A story\",\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "      \"tale\": {\n",
    "        \"type\": \"string\",\n",
    "        \"description\": \"The story\"\n",
    "      }}}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tale': \"It was night, and the moon cast a silver glow over the quiet town. Suddenly, a faint whisper echoed through the streets, 'Find me.' A young girl named Lily felt an inexplicable pull. She followed the whisper to an old, abandoned house on the hill.\"}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "prompt=\"\"\"\"\n",
    "Using the provided template output format,\n",
    "write me a story in 50 words that starts:\n",
    "It was night\n",
    "\"\"\"\"\n",
    "\n",
    "raw_response = w.convert(prompt, output_template=output_template, force=True)\n",
    "\n",
    "json.loads(raw_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting model parameters\n",
    "\n",
    "We can set model parameters by passing a `dict` to the `"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "params={\"max_tokens\":4096,\n",
    "        \"temperature\":0,\n",
    "        \"top_p\": 0.1, \n",
    "        \"frequency_penalty\": 0.0,\n",
    "        \"presence_penalty\": 0.0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In the quiet, moonlit night,\\nA whisper, soft and sweet, does start,\\nA tale, untold, yet so divine,\\nOf love, of dreams, of endless shine.\\n\\nThe stars, like diamonds, twinkle bright,\\nIn the vast, endless, endless night,\\nThe world, a canvas, painted white,\\nOf dreams, of love, of endless light.\\n\\nThe moon, a glowing, glowing eye,\\nGuides the heart, through the endless sky,\\nOf love, of dreams, of endless might,\\nOf hope, in the endless, endless night.\\n\\nThe stars, like diamonds, twinkle bright,\\nIn the vast, endless, endless night,\\nThe world, a canvas, painted white,\\nOf dreams, of love, of endless light.\\n\\nThe moon, a glowing, glowing eye,\\nGuides the heart, through the endless sky,\\nOf love, of dreams, of endless might,\\nOf hope, in the endless, endless night.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.convert(\"write a poem in 8 lines\", params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
